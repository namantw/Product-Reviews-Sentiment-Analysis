{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport re \nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['test.ft.txt.bz2', 'train.ft.txt.bz2']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83a1bb57f5d9371d37daf3ecef4622f419cc06da"
      },
      "cell_type": "code",
      "source": "import bz2\ntrain_file = bz2.BZ2File('../input/train.ft.txt.bz2')\ntest_file = bz2.BZ2File('../input/test.ft.txt.bz2')\n\ntrain_lines = train_file.readlines()\ntest_lines = test_file.readlines()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(len(train_lines), len(test_lines))\n#2 indicates a positive review and 1 indicates a negative review\nprint(train_lines[0])\nprint(train_lines[10])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2d9eef97a004e9a03f7311f31e4b810882c7661c"
      },
      "cell_type": "code",
      "source": "train_lines = [x.decode('utf-8') for x in train_lines]\ntest_lines = [x.decode('utf-8') for x in test_lines]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "50ee4aaed9b585613227fee84ec99aa177da4a9d"
      },
      "cell_type": "code",
      "source": "import re\nfrom tqdm import tqdm\n\ndef pre_process(lines):\n    reviews = []\n    labels = []\n    for line in tqdm(lines):\n#         parse the review and label\n        line = line.split('__label__')[1] \n        label = line[0]\n        review = line[1:]\n        review = review.lower()\n        review = review.split()\n#         ps = PorterStemmer()\n#         review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n        review = ' '.join(review)\n#         sentence=temp[1:len(temp)]\n#         sentence[len(sentence)-1]=sentence[len(sentence)-1][0:len(sentence[len(sentence)-1])-3]\n        \n        reviews.append(review)\n        labels.append(label)\n        \n    return reviews, labels\n        \nreviews_train, labels_train = pre_process(train_lines)\nreviews_test, labels_test = pre_process(test_lines)\n    \n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30995347184551043a36a406475b80a2a4e722d3"
      },
      "cell_type": "code",
      "source": "labels_train = np.array(labels_train)\nlabels_test = np.array(labels_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9541c4069ed9816ca108a1af5ef0b2cd2f14cd8"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words = 10000)\ntokenizer.fit_on_texts(reviews_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c72900505705003eb1377496ddd7dc536994f889"
      },
      "cell_type": "code",
      "source": "token_train = tokenizer.texts_to_sequences(reviews_train)\ntoken_test = tokenizer.texts_to_sequences(reviews_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2fb925af6b2204b8dffc6da8cc02a0332740c981",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "maxlen = 128\nfrom keras.preprocessing.sequence import pad_sequences\nx_train = pad_sequences(token_train, maxlen=128, padding='post')\nx_test = pad_sequences(token_test, maxlen=128, padding='post')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f59fb0ca1654f352fd98c496f272acb9948d39b9",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n\nembed_dim = 128\nmodel = Sequential()\nmodel.add(Embedding(1000, 64,  input_length = x_train.shape[1]))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(32, 7, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(32, 3, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(32, 3, padding='same', activation='relu'))\nmodel.add(Conv1D(2, 1))\nmodel.add(GlobalAveragePooling1D())\nmodel.add(Activation('softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "196790a806cafb8cb56f30f5650ca1719b83696c"
      },
      "cell_type": "code",
      "source": "print(labels_train.shape)\ny_train = []\nfor l in labels_train:\n    if l == '1':\n        l = [0,1]\n    else:\n        l = [1,0]\n    y_train.append(l)\ny_train = np.array(y_train)\nprint(y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6989fcdd914ea0fbc71c32921e3ab0684a7f9df9"
      },
      "cell_type": "code",
      "source": "print(labels_test.shape)\nprint(labels_test)\ny_test = []\nfor l in labels_test:\n    if l == '1':\n        l = [0,1]\n    else:\n        l = [1,0]\n    y_test.append(l)\ny_test = np.array(y_test)\nprint(y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5169e443f80893d1509d94facb90b267f742224"
      },
      "cell_type": "code",
      "source": "size = 200000\nmodel.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53847b783adb130e1622404433de211f90722ea8"
      },
      "cell_type": "code",
      "source": "model.evaluate (x_test, y_test)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f99dd7941cb2f18197c54659b8cc389cb94265cd"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}